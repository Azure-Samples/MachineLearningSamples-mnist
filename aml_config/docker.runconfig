# The script to run.
script: train.py
# The arguments to the script file.
arguments: []
# The name of the compute target to use for this run.
target: local
# Framework to execute inside. Allowed values are "Python" and "PySpark".
framework: PySpark
# Automatically prepare the run environment as part of the run itself.
prepareEnvironment: false
# Environment details
environment:
# Environment variables set for the run.
  environmentVariables:
    EXAMPLE_ENV_VAR: EXAMPLE_VALUE
# Python details
  python:
# user_managed_dependencies=True indicates the environmentwith be user managed. False indicates that AzureML willmanage the user environment.
    userManagedDependencies: false
# The python interpreter path
    interpreterPath: python
# Path to the conda dependencies file to use for this run. If a project
# contains multiple programs with different sets of dependencies, it may be
# convenient to manage those environments with separate files.
    condaDependenciesFile: aml_config/conda_dependencies.yml
# Docker details
  docker:
# enabled=True indicates the docker will be enabled on the target.
    enabled: true
# Base image to use for docker.
    baseImage: microsoft/mmlspark:plus-0.9.9
    sharedVolumes: true
    gpuSupport: false
# Azure container registry to use for getting the docker images.
    baseImageRegistry:
# DNS name or IP address of azure container registry(ACR)
      address:
# The username for ACR
      username:
# The password for ACR
      password:
# Spark details
  spark:
# List of spark repositories.
    repositories:
    - https://mmlspark.azureedge.net/maven
    - https://azuremldownloads.blob.core.windows.net/repo5qh91kdjs6
    packages:
    - group: com.microsoft.ml.spark
      artifact: mmlspark_2.11
      version: 0.9.9
    - group: com.microsoft
      artifact: dprep_2.11
      version: 0.18.0
    - group: com.microsoft.sqlserver
      artifact: mssql-jdbc
      version: 6.2.1.jre8
# History details
history:
# Enable history tracking -- this allows status, logs, metrics, and outputs
# to be collected for a run.
  enabled: true
# Spark configuration details
spark:
  configuration:
    spark.app.name: Azure ML Experiment
    spark.yarn.maxAppAttempts: 1
# HDI details
hdi:
# Yarn deploy mode. Options are cluster and client.
  yarnDeployMode: cluster
# BatchAI details
batchai:
# Number of nodes to use for running batchai jobs
  nodeCount: 1
# Container instance details
containerInstance:
# Number of cores to allocate for the container
  cpuCores: 1
# Memory to allocate for the container in GB
  memoryGb: 4
# Azure region for the container; defaults to the same as workspace
  region:
